# -*- coding: utf-8 -*-
"""LogReg and ML for Cell Detection

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dXFPSniVEfZViNc7KkfwKJX0nexMDcCJ

*Use LogReg to help with cancer prediction*

- Exploring the data
- Visualizing the data

**Predicting Diagnosis: Working up to Logistic Regression using 4 approaches**

- Approach 1: Linear Regression classifier

- Approach 2: Simple boundary classifier

- Approach 3: Modifying with logistic regression

- Approach 4: Multiple feature logistic regression

# Exploring our data
"""

# prompt: load cancer.csv

import pandas as pd
df = pd.read_csv('cancer.csv')

""" ## Looking at our dataset

 A key step in machine learning (and coding in general!) is to view the structure and dimensions of our new dataframe, which stores all our training data from the tumor biopsies. You can think of dataframes like Google or Microsoft Excel spreadsheets (large tables with row/column headers).

We want to confirm that the size of our table is correct, check out the features present, and get a more visual sense of what it looks like overall.
"""

dataframe.head(4)

"""Heres what every column means.

* <u><b><i>diagnosis</u></b></i>: Whether the tumor was diagnosed as malignant (1) or benign (0).
* <u><b><i>perimeter_mean</u></b></i>: The average perimeter of cells in that particular biopsy
* <u><b><i>radius_mean</u></b></i>: The average radius of cells in that particular biopsy
* <u><b><i>texture_mean</u></b></i>: The average texture of cells in that particular biopsy
* <u><b><i>area_mean</u></b></i>: The average area of cells in that particular biopsy
* <u><b><i>smoothness_mean</u></b></i>: The average smoothness of cells in that particular biopsy
* <u><b><i>concavity_mean</u></b></i>: The average concavity of cells in that particular biopsy
* <u><b><i>symmetry_mean</u></b></i>: The average symmetry of cells in that particular biopsy

Recall that the term mean refers to taking an average (summing the values for each cell and dividing by the total number of cells observed in that biopsy).
"""

# Next, we'll use the 'info' method to see the data types of each column
dataframe.info()

#null values are bad, if we have some, we will use data manipulation to make them disappear
dataframe.isnull().sum()

dataframe['diagnosis'].nunique()

""" ## Visualizing our dataset

"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(x = 'radius_mean', y = 'diagnosis_cat', data = dataframe, order=['1 (malignant)', '0 (benign)'])
dataframe.head()

sns.scatterplot(x='radius_mean', y='diagnosis_cat', data=dataframe)





"""# Predicting Diagnosis

Let's start by predicting a diagnosis using a single feature: radius mean.

## Approach 1: Can we use linear regression to classify these cells?
"""

#@title Run this to fit and visualize a linear regression (double-click to see code!)
from sklearn import linear_model

X,y = dataframe[['radius_mean']], dataframe[['diagnosis']]

model = linear_model.LinearRegression()
model.fit(X, y)
preds = model.predict(X)

sns.scatterplot(x='radius_mean', y='diagnosis', data=dataframe)
plt.plot(X, preds, color='r')
plt.legend([ 'Data', 'Linear Regression Fit'])

#@title Make Sure you know what your doing
#@markdown What does a diagnosis of 0.0 mean?
diagnosis_0 = "Choose An Answer" #@param ["Malignant", "Benign", "Choose An Answer"]

#@markdown What does a diagnosis of 1.0 mean?
diagnosis_1 = "Choose An Answer" #@param ["Malignant", "Benign", "Choose An Answer"]

#@markdown What does the model predict for radius_mean = 20?
radius_mean_20 = "Choose An Answer" #@param ["Malignant", "Benign", "Choose An Answer"]

#@markdown What does the model predict for radius_mean = 11?
radius_mean_11 = "Choose An Answer" #@param ["Malignant", "Benign", "Choose An Answer"]

if diagnosis_0 == 'Benign' and diagnosis_1 == 'Malignant':
  print("Correct! 0.0 is a benign prediction and 1.0 is malignant.")
else:
  print("One or both of our diagnoses' interpretations is incorrect. Try again!")

if radius_mean_20 == 'Malignant':
  print("Correct! Our model would predict that a biopsy with radius_mean = 20 is malignant.")
else:
  print("That's not quite what our model would predict for radius_mean = 20. Try again!")

if radius_mean_11 == 'Benign':
  print("Correct! Our model would predict that a biopsy with radius_mean = 11 is benign.")
else:
  print("That's not quite what our model would predict for radius_mean = 11. Try again!")

"""Simple Boundary Classifier
The variable we are trying to predict is categorical, not continuous! So we can't use a linear regression; we have to use a classifier.

### Classification is just drawing boundaries.

The simplest approach to classification is just drawing a boundary. Let's pick a boundary value for the radius mean and see how well it separates the data.
"""

#@title Choose a value for your boundary line and click play!

#@markdown Double-click this cell to see the plotting code.
target_boundary = 14 #@param {type:"slider", min:5, max:30, step:0.5}

sns.boxplot(x = 'radius_mean', y = 'diagnosis_cat', data = dataframe, order=['1 (malignant)', '0 (benign)'])
plt.plot([target_boundary, target_boundary], [-.2, 1.2], 'g', linewidth = 2)

"""### Building the boundary classifier

Here we build a boundary classifier function that takes in a **target boundary**: a particular value of radius mean. This function will take in a boundary value of our choosing and then classify the data points based on whether or not they are above or below the boundary.

**Exercise: Write a function to implement a boundary classifier.** You'll take in a `target_boundary` (a `float` or `int` like 15) and a `radius_mean_series` (a list of values) and return a list of predictions!
"""

def boundary_classifier(target_boundary, radius_mean_series):
  predictions = []

  for radius_mean in radius_mean_series:
    if radius_mean > target_boundary:
      predictions.append(13)
    else:
     predictions.append(0)


  return predictions

"""The code below chooses a boundary and runs your classifier."""

#@title Choose a value for your boundary line and click play to see your classifier at work!

#@markdown Double-click this cell to see the code for `y_pred` and `y_true`.
chosen_boundary = 19 #@param {type:"slider", min:5, max:30, step:0.5}

y_pred = boundary_classifier(chosen_boundary, dataframe['radius_mean'])
dataframe['predicted'] = y_pred

y_true = dataframe['diagnosis']

sns.catplot(x = 'radius_mean', y = 'diagnosis_cat', hue = 'predicted', data = dataframe, order=['1 (malignant)', '0 (benign)'])
plt.plot([chosen_boundary, chosen_boundary], [-.2, 1.2], 'g', linewidth = 2)

"""What do you think of the results based on the graph?

We can take a look at `y_true` and `y_pred` - how similar do they look?
"""

print (list(y_true))
print (y_pred)

"""Let's calculate our accuracy!"""

accuracy = accuracy_score(y_true,y_pred)
print(accuracy)

"""Logistic Regression - using machine learning to determine the optimal boundary

Now, it's time to move away from our simple guess-and-check model and work towards implementing an approach that can automatically find a better separation. One of the most common methods for this is called 'Logistic Regression'.

### Training Data vs Test Data

We'll split up our data set into groups called 'train' and 'test'. We teach our 'model' the patterns using the train data, but the whole point of machine learning is that our prediction should work on 'unseen' data or 'test' data.

The function below does this for you.
"""

from sklearn.model_selection import train_test_split

train_df, test_df = train_test_split(dataframe, test_size = 0.2, random_state = 1)

print('Number of rows in training dataframe:', train_df.shape[0])
train_df.head()

print('Number of rows in test dataframe:', test_df.shape[0])
test_df.head()

"""### Single Variable Logistic Regression

"""

X = ['radius_mean']
y = 'diagnosis'

X_train = train_df[X]
print('X_train, our input variables:')
print(X_train.head())
print()

y_train = train_df[y]
print('y_train, our output variable:')
print(y_train.head())

"""Now, let's prepare our model (we haven't trained it yet):"""

# Import the necessary module
from sklearn import linear_model

# Now you can create your logistic regression model
logreg_model = linear_model.LogisticRegression()

"""###Making Predictions

Next, we want to tell our `logreg_model` object to take in our inputs (X) and our true labels (y) and fit a line that predicts y from X.



"""

logreg_model.fit(X_train,y_train)

"""Testing"""

X_test = test_df[X]
y_test = test_df[y]

"""### Making predictions on our test set

Next, we need to figure out what our line thinks the diagnosis is based on our data points

"""

y_pred = logreg_model.predict(X_test)

"""Run the code below to visualize the results!"""

test_df['predicted'] = y_pred
sns.catplot(x = 'radius_mean', y = 'diagnosis_cat', hue = 'predicted', data=test_df, order=['1 (malignant)', '0 (benign)'])

"""### Finally, let's evaluate the accuracy of our model."""

accuracy = accuracy_score(y_test, y_pred)
print(accuracy)

"""## What is logistic regression doing? It's giving 'soft' predictions!

"""

y_prob = logreg_model.predict_proba(X_test)
X_test_view = X_test[X].values.squeeze()
plt.xlabel('radius_mean')
plt.ylabel('Predicted Probability')
sns.scatterplot(x = X_test_view, y = y_prob[:,1], hue = y_test, palette=['purple','green'])

"""First let's print out one row of our table so we can see what other features we have available to us.

"""

dataframe.head(1)

"""## Can we use multiple features together to do even better?
So far, we've just been using `radius_mean` to make predictions. But there's lots of other potentially important features that we could be using!

Let's take a look again:
"""

dataframe.head(1)

"""### Logistic Regression with Multiple Features"""

# Import necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
import seaborn as sns


train_df, test_df = train_test_split(dataframe, test_size=0.2, random_state=1)

X = ['perimeter_mean', 'texture_mean', 'symmetry_mean']
y = 'diagnosis'

X_train = train_df[X]
y_train = train_df[y]
X_test = test_df[X]
y_test = test_df[y]

logreg_model = LogisticRegression()

logreg_model.fit(X_train, y_train)  # Call fit on the model instance

# Predict on the test data
y_pred = logreg_model.predict(X_test)  # Use logreg_model for prediction


# Visualize results (adjust as needed)
sns.catplot(x='texture_mean', y='diagnosis_cat', hue='predicted',
            data=test_df, order=['1 (malignant)', '0 (benign)'])

print(f'Accuracy: {accuracy:.2f}')

"""Logistic Regression can learn an optimal classification boundary by using multiple features together, which can improve its prediction accuracy even more!

What makes a separation good?

We know our overall accuracy, so we know how many errors we make overall. Errors however come in two kinds:

- **False positives:** The model predicts that a sample is malignant (positive), but it's actually benign.

- **False negatives:** The model predicts that a sample is benign (negative), but it's actually malignant.

###Confusion Matrices
Next, let's evaluate the performance of our model quantitatively. We can visualize statistics on the number of correct vs. incorrect predictions using a confusion matrix that shows the following:

![Confusion Matrix](https://miro.medium.com/max/860/1*7EcPtd8DXu1ObPnZSukIdQ.png)

where the terms mean:

* **TP (True Positive)** = The model predicted positive (malignant in our case, since malignant has a label of 1) and it’s true.
* **TN (True Negative)** = The model predicted negative (benign in our case, since benign has a label of 0) and it’s true.
* **FP (False Positive)** = The model predicted positive and it’s false.
* **FN (False Negative)** = The model predicted negative and it’s false.
"""

#@title Making and visualizing Matrices


# Import the metrics class
from sklearn import metrics

# Create the Confusion Matrix
# y_test = dataframe['diagnosis']
cnf_matrix = metrics.confusion_matrix(y_test, y_pred)

# Visualizing the Confusion Matrix
class_names = [0,1] # Our diagnosis categories

fig, ax = plt.subplots()
# Setting up and visualizing the plot (do not worry about the code below!)
tick_marks = np.arange(len(class_names))
plt.xticks(tick_marks, class_names)
plt.yticks(tick_marks, class_names)
sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap="YlGnBu" ,fmt='g') # Creating heatmap
ax.xaxis.set_label_position("top")
plt.tight_layout()
plt.title('Confusion matrix', y = 1.1)
plt.ylabel('Actual diagnosis')
plt.xlabel('Predicted diagnosis')

#@title Fun MCQ:

#@markdown What are the values in the top left (0, 0)?
top_left = "Choose an Answer" #@param ["True Positives", "True Negatives", "False Positives", "False Negatives", "Choose an Answer"]

#@markdown What are the values in the bottom right (1, 1)?
bottom_right = "Choose an Answer" #@param ["True Positives", "True Negatives", "False Positives", "False Negatives", "Choose an Answer"]

#@markdown What are the values in the top right (1, 0)?
top_right = "Choose an Answer" #@param ["True Positives", "True Negatives", "False Positives", "False Negatives", "Choose an Answer"]

#@markdown What are the values in the bottom left (0, 1)?
bottom_left = "Choose an Answer" #@param ["True Positives", "True Negatives", "False Positives", "False Negatives", "Choose an Answer"]

if top_left == "True Negatives" and bottom_right == "True Positives":
  print("Correct! Our results are True if our model is correct!")
else:
  print("One or both of our (0, 0) and (1, 1) interpretations is incorrect. Try again!")

if top_right == "False Positives":
  print("Correct! A false positive is when our model predicts that a sample is malignant when it's actually benign.")
else:
  print("That's not quite what (1, 0) values are. Try again!")

if bottom_left == "False Negatives":
  print("Correct! A false negative is when our model predicts that a sample is benign when it's actually malignant.")
else:
  print("That's not quite what (0, 1) values are. Try again!")

"""Choosing a Metric

Depending on the situation, we might measure success in different ways. For example, we might use:

- **Accuracy:** What portion of our predictions are right?

- **Precision:** What portion of our positive predictions are actually positive?

- **Recall:** What portion of the actual positives did we identify?

What metric is best?

To calculate any of these, we can use the numbers from our confusion matrix:
"""

print (cnf_matrix)
(tn, fp), (fn, tp) = cnf_matrix
print ("TN, FP, FN, TP:", tn, fp, fn, tp)

"""
 Decision Trees Machine Learning
"""

#@title Create the ML model { display-mode: "both" }
from sklearn import tree

# We'll first specify what model we want, in this case a decision tree
class_dt = tree.DecisionTreeClassifier(max_depth=3)

# We use our previous `X_train` and `y_train` sets to build the model
class_dt.fit(X_train, y_train)

#@title Visualize and interpret the tree
plt.figure(figsize=(13, 8))
tree.plot_tree(class_dt,
               filled=True,
               rounded=True,
               fontsize=10,)

#@title Find the predictions based on the model { display-mode: "both" }
y_pred = class_dt.predict(X_test)

#@title Calculate model performance { display-mode: "both" }
print("Accuracy: ", metrics.accuracy_score(y_test, y_pred))
print("Precision: ", metrics.precision_score(y_test, y_pred))
print("Recall: ", metrics.recall_score(y_test, y_pred))